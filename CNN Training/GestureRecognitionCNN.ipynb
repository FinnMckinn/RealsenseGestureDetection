{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "GestureRecognitionCNN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Nv-iQ06Q-zl"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UeEdk6VARA9q",
        "outputId": "814eab53-0705-41d4-e8b8-033357e83dc6"
      },
      "source": [
        "# Mount google drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dtKRaL1zRXP8"
      },
      "source": [
        "# Misc. Functions\n",
        "\n",
        "# Return all catagories of a data set\n",
        "def setCatagories(directory):\n",
        "  catagories = []\n",
        "  for filename in os.listdir(directory):\n",
        "    catagories.append(filename)\n",
        "  return catagories\n",
        "\n",
        "# Generator for CNN input\n",
        "def gen(subset):\n",
        "    while True:\n",
        "        if subset == \"training\":\n",
        "            for i in TRAINING_DATA.take(1):\n",
        "                img_batch = i\n",
        "            for j in TRAINING_DATA_DEPTH.take(1):\n",
        "                depth_batch = j\n",
        "            for k in y_test.take(1):\n",
        "                labels_batch = k\n",
        "        else:\n",
        "            for i in TESTING_DATA.take(1):\n",
        "                img_batch = i\n",
        "            for j in TESTING_DATA_DEPTH.take(1):\n",
        "                depth_batch = j\n",
        "            for k in y_test.take(1):\n",
        "                labels_batch = k\n",
        "        yield ((img_batch, depth_batch), labels_batch)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4EkvL2glR0ch"
      },
      "source": [
        "# Initial generation functions\n",
        "\n",
        "# Paths to data sets\n",
        "TRAINPATH =       \"/content/drive/MyDrive/Dataset/Glove\"\n",
        "TRAINPATHDEPTH =  \"/content/drive/MyDrive/Dataset/Depth\"\n",
        "\n",
        "TRAINING_DATA = None\n",
        "TESTING_DATA = None\n",
        "\n",
        "TRAINING_DATA_DEPTH = None\n",
        "TESTING_DATA_DEPTH = None\n",
        "\n",
        "# Catagories of data sets\n",
        "CATAGORIES = setCatagories(TRAINPATH)\n",
        "\n",
        "# Global veriables for data creation\n",
        "IMG_SIZE = 480\n",
        "BATCH_SIZE = 8\n",
        "\n",
        "# Finds image data and applys pre-processing\n",
        "def create_set(path, setType):\n",
        "  dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    path,\n",
        "    validation_split=0.2,\n",
        "    subset=setType,\n",
        "    seed=123,\n",
        "    image_size=(IMG_SIZE, IMG_SIZE),\n",
        "    batch_size=BATCH_SIZE)\n",
        "  return dataset\n",
        "\n",
        "# Create and process data for use in CNN\n",
        "def initial_setup():\n",
        "  global TRAINING_DATA, TESTING_DATA, TRAINING_DATA_DEPTH, TESTING_DATA_DEPTH\n",
        "\n",
        "  print(\"Creating image training data...\")\n",
        "  TRAINING_DATA = create_set(TRAINPATH, \"training\")\n",
        "  print(\"Image training data created!\")\n",
        "\n",
        "  print(\"Creating image testing data...\")\n",
        "  TESTING_DATA = create_set(TRAINPATH, \"validation\")\n",
        "  print(\"Image testing data created!\")\n",
        "\n",
        "  print(\"Image data complete \\n\")\n",
        "\n",
        "  print(\"Creating depth training data...\")\n",
        "  TRAINING_DATA_DEPTH = create_set(TRAINPATHDEPTH, \"training\")\n",
        "  print(\"Depth training data created!\")\n",
        "\n",
        "  print(\"Creating depth testing data...\")\n",
        "  TESTING_DATA_DEPTH = create_set(TRAINPATHDEPTH, \"validation\")\n",
        "  print(\"Depth testing data created!\")\n",
        "\n",
        "  print(\"Depth data complete \\n\")\n",
        "\n",
        "initial_setup()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dp6X4ULUNS49"
      },
      "source": [
        "# Tune and normalise data\n",
        "\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "TRAINING_DATA = TRAINING_DATA.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
        "TESTING_DATA = TESTING_DATA.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "TRAINING_DATA_DEPTH = TRAINING_DATA_DEPTH.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
        "TESTING_DATA_DEPTH = TESTING_DATA_DEPTH.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "normalization_layer = layers.experimental.preprocessing.Rescaling(1./255)\n",
        "\n",
        "normalized_ds = TRAINING_DATA.map(lambda x, y: (normalization_layer(x), y))\n",
        "normalized_ds_depth = TRAINING_DATA_DEPTH.map(lambda x, y: (normalization_layer(x), y))\n",
        "\n",
        "y_train = tf.data.Dataset.from_tensor_slices(tf.random.uniform((262,1))).batch(BATCH_SIZE)\n",
        "y_test = tf.data.Dataset.from_tensor_slices(tf.random.uniform((65,1))).batch(BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ISps4P7RrBH"
      },
      "source": [
        "# Apply data to generator\n",
        "gen_train = gen(\"training\")\n",
        "gen_valid = gen(\"validation\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9kVc4Mz3XywG"
      },
      "source": [
        "# shapes as you said in comments\n",
        "img_data_shape = (480, 480, 3)\n",
        "dep_data_shape = (480, 480, 3)\n",
        "num_classes = 3\n",
        "\n",
        "# define two inputs layers\n",
        "img_input = tf.keras.layers.Input(shape=img_data_shape, name=\"image\")\n",
        "depth_input = tf.keras.layers.Input(shape=dep_data_shape, name=\"depth\")\n",
        "\n",
        "# Layers for image data \n",
        "x1 = tf.keras.layers.experimental.preprocessing.Rescaling(1./255)(img_input)\n",
        "x1 = tf.keras.layers.Conv2D(16, 3, padding='same', activation='relu', name=\"conv1_img\")(x1)\n",
        "x1 = tf.keras.layers.MaxPooling2D(name=\"maxp1_img\")(x1)\n",
        "x1 = tf.keras.layers.Conv2D(32, 3, padding='same', activation='relu', name=\"conv2_img\")(x1)\n",
        "x1 = tf.keras.layers.MaxPooling2D(name=\"maxp2_img\")(x1)\n",
        "x1 = tf.keras.layers.Conv2D(64, 3, padding='same', activation='relu', name=\"conv3_img\")(x1)\n",
        "x1 = tf.keras.layers.MaxPooling2D(name=\"maxp3_img\")(x1)\n",
        "x1 = tf.keras.layers.Flatten(name=\"flatten_img\")(x1)\n",
        "\n",
        "\n",
        "# Layers for depth data\n",
        "x2 = tf.keras.layers.experimental.preprocessing.Rescaling(1./255)(depth_input)\n",
        "x2 = tf.keras.layers.Conv2D(16, 3, padding='same', activation='relu', name=\"conv1_depth\")(x2)\n",
        "x2 = tf.keras.layers.MaxPooling2D(name=\"maxp1_depthg\")(x2)\n",
        "x2 = tf.keras.layers.Conv2D(32, 3, padding='same', activation='relu', name=\"conv2_depth\")(x2)\n",
        "x2 = tf.keras.layers.MaxPooling2D(name=\"maxp2_depth\")(x2)\n",
        "x2 = tf.keras.layers.Conv2D(64, 3, padding='same', activation='relu', name=\"conv3_depth\")(x2)\n",
        "x2 = tf.keras.layers.MaxPooling2D(name=\"maxp3_depth\")(x2)\n",
        "x2 = tf.keras.layers.Flatten(name=\"flatten_depth\")(x2)\n",
        "\n",
        "# Merge\n",
        "x = tf.keras.layers.concatenate([x1,x2], name=\"concat_depth_img\")\n",
        "x = tf.keras.layers.Dense(128, activation='relu', name=\"dense1_both\")(x)\n",
        "output = tf.keras.layers.Dense(num_classes, name=\"classify\")(x)\n",
        "\n",
        "# Model for two inputs and an output\n",
        "model = tf.keras.models.Model(inputs=[img_input, depth_input], outputs=output)\n",
        "model.summary()\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QBS82JKWCfcu"
      },
      "source": [
        "# Train Model\n",
        "histroy = model.fit(gen_train, epochs=20, steps_per_epoch=3, validation_data=gen_valid, validation_steps=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UrGCiecaR-YH"
      },
      "source": [
        "#Save Model\n",
        "model.save('/content')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}